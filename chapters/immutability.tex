\setchapterpreamble[u]{\margintoc}
\chapter{Immutability}
\labch{immutability}

\textit{Immutability}\index{immutability} means not changing.
Immutable variables never change their values
after initialization; immutable data structures never change their elements
once created. The opposite of immutability is mutability. While imperative
programming uses numerous mutable variables, data structures, and objects,
functional programming leverages the power of immutable varibles, data
structures, and objects. This chapter explains why immutability is important and
valuable. Also, we will see how to program without mutation.

\section{Advantages}

The book Programming in Scala~\cite{programming-in-scala}
discusses four strengths of immutability:

\begin{quote}
First, immutable objects are often easier to reason about than mutable ones,
because they do not have complex state spaces that change over time. Second, you
can pass immutable objects around quite freely, whereas you may need to make
defensive copies of mutable objects before passing them to other code. Third,
there is no way for two threads concurrently accessing an immutable to corrupt
its state once it has been properly constructed, because no thread can change the
state of an immutable. Fourth, immutable objects make safe hash table keys. If a
mutable object is mutated after it is placed into a \code{HashSet}, for example,
that object may not be found the next time you look into the \code{HashSet}.
\end{quote}

We will focus on the first two advantages:
easier reasoning and no need for defensive copies.

First, let us see why immutability makes things easy to reason about.

\begin{verbatim}
val x = 1
...
f(x)
\end{verbatim}

At the first line of the code, \code{x} is \code{1}. Since \code{x} is immutable,
there is no doubt that \code{x} is still \code{1} when \code{x} is passed as an
argument for \code{f} at the last line of the code.

\begin{verbatim}
var x = 1
...
f(x)
\end{verbatim}

On the other hand, if \code{x} is a mutable variable, one should read every line
of code in the middle to find the value of \code{x} at the time when the function
call happens.

When \code{x} is mutable, without tracking every
modification of \code{x} throughout the code, the value of \code{x} at the last
line is unknown. It hampers programmers from understanding the code
and possibly leads to more bugs.
The program with immutable \code{x} does not suffer from such problems.
Remembering only one line of the code is enough to track the value of \code{x}.

Mutable data structures cause similar problems.

\begin{verbatim}
val x = List(1, 2)
...
f(x)
...
x
\end{verbatim}

As \code{List} is immutable,
\code{x} is a list always containing \code{1} and \code{2}.

\begin{verbatim}
import scala.collection.mutable.ListBuffer
val x = ListBuffer(1, 2)
...
f(x)
...
x
\end{verbatim}

On the other hand, \code{ListBuffer} is a mutable data structure in the Scala
standard library. It is possible to add an item to or remove an item from the
list referred by \code{x}. Programmers cannot be certain about the content of \code{x}
unless they read all the lines in between. Besides, a function \code{f} also is
able to change the content of \code{x}. If one writes a program with a wrong
assumption that \code{f} does not modify \code{x}, then the program might be
buggy.

Mutable global variables make code much harder to understand than mutable local
variables.

\begin{verbatim}
def f(x: Int) = g(x, y)
\end{verbatim}

The return value of function \code{f} depends on the value of a global variable
\code{y}. If \code{y} is mutable, \code{f} is not a pure function and expecting
the behavior of \code{f} is nontrivial. \code{y} can be declared in any arbitrary
file and all files are able to change the value of \code{y}.
In the worst case, an external library defines \code{y} and source code
modifying \code{y} is not available for reading.

The examples are small and seem artificial, but immutability greatly improves
maintainability and readability of code in practice, especially for large
projects.

Now, let us see why immutability free us from making defensive copies.

\begin{verbatim}
val x = ListBuffer(1, 2)
...
f(x)
...
x
\end{verbatim}

Since \code{ListBuffer} creates mutable lists, there is no guarantee that the
content of \code{x} is not changed by \code{f}. If it is necessary to prevent
modification, copying \code{x} is essential.

\begin{verbatim}
val x = ListBuffer(1, 2)
val y = x.clone
...
f(y)
...
x
\end{verbatim}

In cases that \code{x} has many elements and the code is executed multiple times,
copying \code{x} increases the execution time significantly.

In the code, using the \code{clone} method is enough to copy the list because the
list contains only integers. However, to pass lists containing mutable
objects safely to functions, defining additional methods for deep copy is
inevitable.

Immutability has several clear advantages. Immutability is an important concept in
functional programming. Functional programs use immutable variables and data
structures in most cases. If you write a large program whose logic is complex
and correctness is important, you should adopt the functional paradigm.
However, mind that immutability is not the silver bullet for every
program. For example, implementing algorithms in a functional style is usually
inefficient. It would be better to use mutable data structures like arrays,
mutable variables, and loops to implement algorithms. They make
programs much more efficient and faster. Choosing a programming proper paradigm for
the purpose of a program is the key to write good code.

\section{Recursion}
\labsec{recursion}

Repeating the same computation multiple times is a common pattern in programming.
Loops allow concise code expressing such cases. However, if everything is
immutable, going back to the beginnings of loops does not change any states.
Therefore, it is impossible to apply the same operation on different values for
each iteration or to terminate the loops. As a consequence, loops are useless in
functional programming. Functional programs use recursive functions instead of
loops to rerun computation. A \textit{recursive}\index{recursion}
function is a function that calls itself.\sidenote{In general, a definition that
refers to itself is a recursive definition. There can be recursive variables,
recursive types, and so on.}
To do more computation, the function calls itself with proper arguments.
Otherwise, it terminates the computation by returning some value.

The below \code{factorial} function calculates the factorial of a given integer.
For simplicity, we do not consider when the input is negative.
The following implementation uses an imperative style:

\begin{verbatim}
def factorial(n: Int) = {
  var i = 1, res = 1
  while (i <= n) {
    res *= i
    i += 1
  }
  res
}
\end{verbatim}

We can implement the same function in a functional style with recursion.

\begin{verbatim}
def factorial(n: Int): Int =
  if (n <= 0)
    1
  else
    n * factorial(n - 1)
\end{verbatim}

Note that recursive functions always require explicit return types in Scala,
unlike non-recursive functions, whose return types can be omitted.

The recursive version is preferred over the imperative version since its
correctness is easily verified.

To check the correctness of the imperative
\code{factorial} function, one should find a \textit{loop invariant}\index{loop invariant},
which is a proposition that is always true at the loop head.
The loop invariant of this case is
$((\code{i}-1)!=\code{res})\land(\code{i}\le\code{n}+1)$.
By using this invariant, we can conclude that $\code{i}=\code{n}+1$ and,
therefore, $\code{res}=(\code{i}-1)!=\code{n}!$ at the last line of the
function, which implies that it correctly implements factorial.
It is nontrivial to find a proper loop invariant and show that the loop invariant
holds at the beginning of each iteration.

On the other hand,
recursive functions usually reveal their mathematical definitions more clearly
than functions using loops. Consider the following mathematical definition of
factorial:

\[n!=\begin{cases}1 & \text{if } n=0\\n \times (n-1)! &
\text{otherwise}\end{cases}\]

You can see that the implementation of the \code{factorial} function using recursion
is identical to the mathematical definition of factorial. It is almost trivial
to show that the recursive \code{factorial} function is correct.
Recursion allows concise and intuitive descriptions of mathematical functions.
In many cases, functions with recursion is much easier to be verified formally
or informally than functions with loops.

Recursive functions are also good at treating recursive data structures like
lists. A list is recursive since a nonempty list consists of a head element
and a tail list, which means that a nonempty list has another list as its component.
Writing some functions regarding lists helps understanding and practicing
recursion.

The following function takes a list as an argument and returns a list whose
elements are one larger than the elements of the given list.

\begin{verbatim}
def inc1(l: List[Int]): List[Int] = l match {
  case Nil => Nil
  case h :: t => h + 1 :: inc1(t)
}
\end{verbatim}

When a given list is empty, the function returns the empty list. Otherwise, the
return value is a list whose head is one larger than the head of the given list
and tail has elements that are one larger than the elements of the tail of the
given list.

Similarly, \code{square} takes a list of integers as an argument and returns a
list whose elements are the squares of the elements of the given list.

\begin{verbatim}
def square(l: List[Int]): List[Int] = l match {
  case Nil => Nil
  case h :: t => h * h :: square(t)
}
\end{verbatim}

The following function takes a list of integers as an argument and returns a list whose
elements are odd integers.

\begin{verbatim}
def odd(l: List[Int]): List[Int] = l match {
  case Nil => Nil
  case h :: t =>
    if (h % 2 != 0)
      h :: odd(t)
    else
      odd(t)
}
\end{verbatim}

For a nonempty list, the function checks whether the head is odd or not. If the
head is odd, the resulting list contains the head, and its tail  has
only odd integers. Otherwise, the head is removed.

Similarly, \code{positive} takes a list of integers as an argument and returns a
list whose elements are positive.

\begin{verbatim}
def positive(l: List[Int]): List[Int] = l match {
  case Nil => Nil
  case h :: t =>
    if (h > 0)
      h :: positive(t)
    else
      positive(t)
}
\end{verbatim}

The following function calculates the sum of the elements of a given list.

\begin{verbatim}
def sum(l: List[Int]): Int = l match {
  case Nil => 0
  case h :: t => h + sum(t)
}
\end{verbatim}

The sum of elements in the empty list is zero as there are no elements.
When a list is nonempty, the sum of its elements can be calculated by adding the
value of the head to the sum of its tail's elements.

Similarly, \code{product} calculates the product of the elements of a given
list.

\begin{verbatim}
def product(l: List[Int]): Int = l match {
  case Nil => 1
  case h :: t => h * product(t)
}
\end{verbatim}

Recursion has some disadvantages: overheads of function calls and stack
overflow. Most modern CPUs have enough computing power to ignore function call
overheads. However, loops are still more ideal than recursive functions in
performance-critical programs. Stack overflow happens when a
stack lacks space due to repetitive function calls. It is a critical problem
since it causes immediate termination of execution without yielding meaningful
output. Moreover, programs like web servers do not finish their execution, and
their stacks will eventually overflow. To prevent stack overflow, many functional
languages provide tail call optimization.
The following section explains tail call optimization in detail.

\section{Tail Call Optimization}
\labsec{tco}

If the last action of a function is a function call, then the call is a tail
call. When a tail call happens, the callee does every computation, and thus the
local variables of the caller have no need to remain after the call. The stack
frame of the caller can be destroyed. Most functional languages exploit this
fact to optimize tail calls. This optimization is called
\textit{tail call optimization}.\index{tail call optimization}
At compile time, compilers check whether calls are tail calls.
If a call is a tail call, the compilers generate code that eliminates the
stack frame of the caller before the call. They do not optimize non-tail function
calls because the local variables of the callers can be used after the callees
return. If every function call in a program is a tail call, the stack never
grows so that the program is safe from stack overflow.

\begin{verbatim}
def factorial(n: Int): Int =
  if (n <= 0)
    1
  else
    n * factorial(n - 1)
\end{verbatim}

The previous \code{factorial} function multiplies \code{n} and the return value
of the recursive \code{factorial(n - 1)} call. The multiplication is the last
action. The recursive call is not a tail call. The stack frame of the caller must
remain. The following process computes \code{factorial(3)}:

\begin{itemize}
\item \code{factorial(3)}
\item \code{3 * factorial(2)}
\item \code{3 * (2 * factorial(1))}
\item \code{3 * (2 * (1 * factorial(0)))}
\item \code{3 * (2 * (1 * 1))}
\item \code{3 * (2 * 1)}
\item \code{3 * 2}
\item \code{6}
\end{itemize}

At most four stack frames coexist. For a large argument, a stack grows
again and again and finally overflows.

\begin{verbatim}
factorial(10000)
\end{verbatim}
\vspace{-1em}
\begin{mdframed}[hidealllines=true,backgroundcolor=red!10,innerleftmargin=3pt,innerrightmargin=3pt,leftmargin=-3pt,rightmargin=-3pt]
\begin{verbatim}
java.lang.StackOverflowError
  at .factorial
\end{verbatim}
\vspace{-2em}
\begin{flushright}
\scriptsize\textsf{Run-time error}
\end{flushright}
\end{mdframed}

To implement the function with a tail call, instead of multiplying \code{n} and
\code{factorial(n - 1)}, the function has to pass both \code{n} and \code{n - 1}
as arguments and make the callee multiply \code{n} and $(\code{n - 1})!$.
This strategy can be interpreted as passing an intermediate result.

\begin{itemize}
\item \code{factorial(3)}
\item \code{factorial(2, intermediate result = 3)}
\item \code{factorial(1, intermediate result = 3 * 2)}
\item \code{factorial(1, intermediate result = 6)}
\item \code{factorial(0, intermediate result = 6 * 1)}
\item \code{factorial(0, intermediate result = 6)}
\item \code{6}
\end{itemize}

There is no need to return to the caller. The below code shows the
\code{factorial} function with a tail call. The function needs one more parameter
that takes an intermediate result as an argument.
\code{factorial(n, i)} computes \(\code{n}!\times\code{i}\).

\begin{verbatim}
def factorial(n: Int, inter: Int): Int =
  if (n <= 0)
    inter
  else
    factorial(n - 1, inter * n)
\end{verbatim}

The function uses a tail call. More precisely, the function is
tail-recursive. Its last action is calling itself. Unlike most functional
languages, Scala cannot optimize general tail calls. Scala optimizes only
tail-recursive calls.
The Scala compiler generates Java bytecode, which is executed by the JVM. The JVM does not
allow bytecode to jump to the beginning of another function. In the JVM, functions can
only either return or call functions. Therefore, the Scala compiler cannot generate
optimized code by removing the stack frame of a caller. Instead, they transform
tail-recursive calls into loops.
The \code{factorial} function is compiled to the following bytecode:

\begin{verbatim}
public int factorial(int, int);
  Code:
     0: iload_1
     1: iconst_0
     2: if_icmpgt     9
     5: iload_2
     6: goto          20
     9: iload_1
    10: iconst_1
    11: isub
    12: iload_2
    13: iload_1
    14: imul
    15: istore_2
    16: istore_1
    17: goto          0
    20: ireturn
\end{verbatim}

We can check that there is no function call at
all.\sidenote{\code{invokevirtual} is a function call instruction.}
The function just jumps to instructions inside the function.
Due to the tail call optimization, the function never incurs stack overflow.

Even with tail recursion,
the result is still incorrect because of integer overflow.

\begin{verbatim}
assert(factorial(10000, 1) == 0)  // weird result
\end{verbatim}

The \code{BigInt} type resolves integer overflow.

\begin{verbatim}
def factorial(n: BigInt, inter: BigInt): BigInt =
  if (n <= 0)
    inter
  else
    factorial(n - 1, inter * n)

assert(factorial(10000, 1) > 0)
\end{verbatim}

The optimization of the Scala compiler not only prevents stack overflow but also removes the
overheads of function calls. The downside is that mutually recursive
functions using tail calls lie beyond the scope of the optimization.
Mutual recursion is recursion involving two or more definitions.
The following functions can cause stack overflow in Scala even though they use tail
calls because they are not tail-recursive:

\begin{verbatim}
def even(n: Int): Boolean = if (n <= 0) true else odd(n - 1)
def odd(n: Int): Boolean = if (n == 1) true else even(n - 1)
\end{verbatim}

In Scala, programmers can ask the compiler to check
whether functions are tail-recursive with annotations. The annotations prevent
programmers from making functions non-tail-recursive by mistakes.

\begin{verbatim}
import scala.annotation.tailrec
@tailrec def factorial(n: BigInt, inter: BigInt): BigInt =
  if (n <= 0)
    inter
  else
    factorial(n - 1, inter * n)
\end{verbatim}

A non-tail-recursive function with the \code{tailrec} annotation results in a
compile-time error.

\begin{verbatim}
@tailrec def factorial(n: Int): Int =
  if (n <= 0)
    1
  else
    n * factorial(n - 1)
\end{verbatim}
\vspace{-1em}
\begin{mdframed}[hidealllines=true,backgroundcolor=red!10,innerleftmargin=3pt,innerrightmargin=3pt,leftmargin=-3pt,rightmargin=-3pt]
\begin{verbatim}
      ^
error:
could not optimize @tailrec annotated method factorial:
it contains a recursive call not in tail position
\end{verbatim}
\vspace{-1.5em}
\begin{flushright}
\scriptsize\textsf{Compile-time error}
\end{flushright}
\end{mdframed}

The annotation does not affect the behavior of the resulting bytecode.
Regardless of the existence of the annotation, the compiler always optimizes
tail-recursive functions. Still, using the annotations is desirable to prevent
mistakes.

Calling the tail-recursive version of \code{factorial} needs the unnecessary
second argument. The below code defines a new \code{factorial} function with one
parameter and uses the tail-recursive one as a local function inside the
function.

\begin{verbatim}
def factorial(n: BigInt): BigInt = {
  @tailrec def aux(n: BigInt, inter: BigInt): BigInt =
    if (n <= 0)
      inter
    else
      aux(n - 1, inter * n)
  aux(n, 1)
}
\end{verbatim}

Some functions treating lists also can be rewritten in a tail-recursive way.
Below is a tail-recursive version of \code{sum}.

\begin{verbatim}
def sum(l: List[Int]): Int = {
  @tailrec def aux(l: List[Int], inter: Int): Int = l match {
    case Nil => inter
    case h :: t => aux(t, inter + h)
  }
  aux(l, 0)
}
\end{verbatim}

\code{aux(l, n)} calculates \code{n} plus the sum of \code{l}'s elements.

Similarly, \code{product} can be implemented in a tail-recursive way.

\begin{verbatim}
def product(l: List[Int]): Int = l match {
  @tailrec def aux(l: List[Int], inter: Int): Int = l match {
    case Nil => inter
    case h :: t => aux(t, inter * h)
  }
  aux(l, 1)
}
\end{verbatim}

\section{Exercises}

\begin{exercise}
\labex{immutability-student}

Consider the following definition of \code{Student}:
\begin{verbatim}
case class Student(name: String, height: Int)
\end{verbatim}
Implement a function \code{names}:
\begin{verbatim}
def names(l: List[Student]): List[String] = ???
\end{verbatim}
that takes a list of students as an argument
and returns a list containing the names of the students.

\end{exercise}

\begin{exercise}
\labex{immutability-tall}

Consider the same definition of \code{Student}.
Implement a function \code{tall}:
\begin{verbatim}
def tall(l: List[Student]): List[Student] = ???
\end{verbatim}
that takes a list of students as an argument
and returns a list of students whose heights are greater than 170.

\end{exercise}

\begin{exercise}
\labex{immutability-length}

Implement a function \code{length}:
\begin{verbatim}
def length(l: List[Int]): Int = ???
\end{verbatim}
that takes a list of integers as an argument
and returns the length of the list.

Remark that there is a built-in method \code{l.length}, but try to implement
yourself using recursive function.

\end{exercise}

\begin{exercise}
\labex{immutability-append}

Implement a function \code{append}:
\begin{verbatim}
def append(l: List[Int], n: Int): List[Int] = ???
\end{verbatim}
that takes a list of integers and an integer as arguments
and returns a list obtained by appending the integer at the end of the list.
Then, compare the time complexity of appending a new element to that of
prepending a new element by \code{::}, which is $O(1)$.

Remark that there is a built-in method \code{l.appended(n)}, but try to implement
yourself using recursive function.

\end{exercise}
